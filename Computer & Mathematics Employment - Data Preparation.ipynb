{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Sources\n",
    "naturls = ['https://www.bls.gov/oes/special.requests/oesm17in4.zip', \n",
    "'https://www.bls.gov/oes/special.requests/oesm16in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm15in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm14in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm13in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm12in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm11in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm10in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm09in4.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm08in4.zip']\n",
    "\n",
    "natzip = ['data/raw/oesm17in4.zip', \n",
    "'data/raw/oesm16in4.zip',\n",
    "'data/raw/oesm15in4.zip',\n",
    "'data/raw/oesm14in4.zip',\n",
    "'data/raw/oesm13in4.zip',\n",
    "'data/raw/oesm12in4.zip',\n",
    "'data/raw/oesm11in4.zip',\n",
    "'data/raw/oesm10in4.zip',\n",
    "'data/raw/oesm09in4.zip',\n",
    "'data/raw/oesm08in4.zip']\n",
    "\n",
    "natData = {'2008': {\n",
    "            'inFiles': {\n",
    "                1: {'filename': \"./Data/raw/nat3d_M2008_dl.xls\", 'sheet': \"nat3d_dl\"}\n",
    "            },\n",
    "            'outFile': 'data/preprocessed/nat2008.csv',\n",
    "            },\n",
    "           '2009': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/nat3d_M2009_dl.xls\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2009.csv', \n",
    "           },\n",
    "           '2010': {\n",
    "               'inFiles': {\n",
    "                   1: {'filename': \"./Data/raw/nat3d_M2010_dl.xls\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2010.csv', \n",
    "           },\n",
    "           '2011': {\n",
    "               'inFiles': { \n",
    "                1: {'filename': \"./Data/raw/nat3d_M2011_dl.xls\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2011.csv', \n",
    "           },\n",
    "           '2012': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/oesm12in4/nat3d_M2012_dl.xls\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2012.csv', \n",
    "           },\n",
    "           '2013': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/oesm13in4/nat3d_M2013_dl.xls\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2013.csv', \n",
    "           },\n",
    "           '2014': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/oesm14in4/nat3d_M2014_dl.xlsx\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2014.csv', \n",
    "           },\n",
    "           '2015': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/oesm15in4/nat3d_M2015_dl.xlsx\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2015.csv', \n",
    "           },\n",
    "           '2016': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/oesm16in4/nat3d_M2016_dl.xlsx\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2016.csv', \n",
    "           },\n",
    "           '2017': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/oesm17in4/nat3d_M2017_dl.xlsx\", 'sheet': \"nat3d_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/nat2017.csv', \n",
    "           }\n",
    "        }\n",
    "nat2017Data = {\n",
    "    'url': 'https://www.bls.gov/oes/special.requests/oesm17nat.zip',\n",
    "    'zipfile' : \"./data/raw/noesm17nat.zip\",\n",
    "    'excelfile' : \"./data/raw/oesm17nat/national_M2017_dl.xlsx\",\n",
    "    'sheet': 'national_dl'\n",
    "}\n",
    "natfile = \"./data/preprocessed/nat.csv\"\n",
    "nat2017file = \"./data/preprocessed/natocc2017.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Sources\n",
    "urls = ['https://www.bls.gov/oes/special.requests/oesm17ma.zip', \n",
    "'https://www.bls.gov/oes/special.requests/oesm16ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm15ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm14ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm13ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm12ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm11ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm10ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm09ma.zip',\n",
    "'https://www.bls.gov/oes/special.requests/oesm08ma.zip']\n",
    "\n",
    "oeszip = ['data/raw/oesm17ma.zip', \n",
    "'data/raw/oesm16ma.zip',\n",
    "'data/raw/oesm15ma.zip',\n",
    "'data/raw/oesm14ma.zip',\n",
    "'data/raw/oesm13ma.zip',\n",
    "'data/raw/oesm12ma.zip',\n",
    "'data/raw/oesm11ma.zip',\n",
    "'data/raw/oesm10ma.zip',\n",
    "'data/raw/oesm09ma.zip',\n",
    "'data/raw/oesm08ma.zip']\n",
    "\n",
    "oesData = {'2008': {\n",
    "            'inFiles': {\n",
    "                1: {'filename': \"./Data/raw/MSA__M2008_dl_1.xls\", 'sheet': \"MSA_dl_1\"},\n",
    "                2: {'filename': \"./Data/raw/MSA_M2008_dl_2.xls\", 'sheet': \"MSA_dl_2\"},\n",
    "                3: {'filename': \"./Data/raw/MSA_M2008_dl_3.xls\", 'sheet': \"MSA_dl_3\"}\n",
    "            },\n",
    "            'outFile': 'data/preprocessed/oes2008.csv',\n",
    "            },\n",
    "           '2009': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/MSA_dl_1.xls\", 'sheet': \"MSA_dl_1\"},\n",
    "                   2: {'filename': \"./Data/raw/MSA_dl_2.xls\", 'sheet': \"MSA_dl_2\"},\n",
    "                   3: {'filename': \"./Data/raw/MSA_dl_3.xls\",'sheet': \"MSA_dl_3\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2009.csv', \n",
    "           },\n",
    "           '2010': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/MSA_M2010_dl_1.xls\", 'sheet': \"MSA_dl_1\"},\n",
    "                   2: {'filename': \"./Data/raw/MSA_M2010_dl_2.xls\", 'sheet': \"MSA_dl_2\"},\n",
    "                   3: {'filename': \"./Data/raw/MSA_M2010_dl_3.xls\", 'sheet': \"MSA_dl_3\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2010.csv', \n",
    "           },\n",
    "           '2011': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/MSA_M2011_dl_1_AK_IN.xls\", 'sheet': \"MSA_dl_1\"},\n",
    "                   2: {'filename': \"./Data/raw/MSA_M2011_dl_2_KS_NY.xls\", 'sheet': \"MSA_dl_2\"},\n",
    "                   3: {'filename': \"./Data/raw/MSA_M2011_dl_3_OH_WY.xls\", 'sheet': \"MSA_dl_3\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2011.csv', \n",
    "           },\n",
    "           '2012': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/MSA_M2012_dl_1_AK_IN.xls\", 'sheet': \"MSA_dl_1\"},\n",
    "                   2: {'filename': \"./Data/raw/MSA_M2012_dl_2_KS_NY.xls\", 'sheet': \"MSA_dl_2\"},\n",
    "                   3: {'filename': \"./Data/raw/MSA_M2012_dl_3_OH_WY.xls\", 'sheet': \"MSA_dl_3\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2012.csv', \n",
    "           },\n",
    "           '2013': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./Data/raw/MSA_M2013_dl_1_AK_IN.xls\", 'sheet': \"MSA_dl_1\"},\n",
    "                   2: {'filename': \"./Data/raw/MSA_M2013_dl_2_KS_NY.xls\", 'sheet': \"MSA_dl_2\"},\n",
    "                   3: {'filename': \"./Data/raw/MSA_M2013_dl_3_OH_WY.xls\", 'sheet': \"MSA_dl_3\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2013.csv', \n",
    "           },\n",
    "           '2014': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./data/raw/oesm14ma/MSA_M2014_dl.xlsx\", 'sheet': \"MSA_dl\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2014.csv', \n",
    "           },\n",
    "           '2015': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./data/raw/oesm15ma/MSA_M2015_dl.xlsx\", 'sheet': \"MSA_dl_1\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2015.csv', \n",
    "           },\n",
    "           '2016': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./data/raw/oesm16ma/MSA_M2016_dl.xlsx\", 'sheet': \"MSA_dl_1\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2016.csv', \n",
    "           },\n",
    "           '2017': {\n",
    "               'inFiles': { \n",
    "                   1: {'filename': \"./data/raw/oesm17ma/MSA_M2017_dl.xlsx\", 'sheet': \"MSA_dl_1\"}\n",
    "               },\n",
    "               'outFile': 'data/preprocessed/oes2017.csv', \n",
    "           }\n",
    "        }\n",
    "oesfile = \"./data/preprocessed/oes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(urls, files):\n",
    "    for i, j in zip(urls, files):\n",
    "        urllib.request.urlretrieve(i, j)\n",
    "        with zipfile.ZipFile(j) as oeszip:\n",
    "            oeszip.extractall(path = 'data/raw/')\n",
    "            os.remove(oeszip)\n",
    "    \n",
    "    urllib.request.urlretrieve(nat2017Data['url'], nat2017Data['zipfile'])\n",
    "    with zipfile.ZipFile(nat2017Data['zipfile']) as natzip:\n",
    "        natzip.extractall(path='data/raw')\n",
    "    \n",
    "#getData(naturls, natzip)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(nat2017['url'], nat2017['zipfile'])\n",
    "with zipfile.ZipFile(nat2017['zipfile']) as natzip:\n",
    "    natzip.extractall(path='data/raw')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepNATData():\n",
    "    directory = \"./data/preprocessed\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    dfcols = ['YEAR', 'NAICS', 'NAICS_TITLE', 'OCC_CODE', 'OCC_TITLE', 'TOT_EMP',\n",
    "              'EMP_PRSE', 'A_MEAN', 'MEAN_PRSE', 'A_MEDIAN',\n",
    "              'TOT_EMP_SE', 'TOT_EMP_ME', 'A_MEAN_SE', 'A_MEAN_ME', \n",
    "              'A_MEDIAN_SE', 'A_MEDIAN_ME']\n",
    "    allData = []\n",
    "    for year, info in natData.items():\n",
    "        \n",
    "        # Concatenate files\n",
    "        dfs = []\n",
    "        for file in info['inFiles']:\n",
    "            xl = pd.ExcelFile(info['inFiles'][file]['filename'])\n",
    "            pdf = xl.parse(info['inFiles'][file]['sheet'])\n",
    "            dfs.append(pdf)\n",
    "        df = pd.concat(dfs)\n",
    "        \n",
    "        # Remove NAs, missing values, and convert strings to numeric, and add year to dataframe\n",
    "        df = (df\n",
    "              .replace([\"**\", \"*\", \"#\"], pd.np.nan).dropna(axis=0, how = 'any',\n",
    "                                                          subset = ['TOT_EMP', 'EMP_PRSE',\n",
    "                                                                    'A_MEAN', 'MEAN_PRSE',\n",
    "                                                                    'A_MEDIAN'])\n",
    "              .apply(pd.to_numeric, errors = 'ignore')\n",
    "              .assign(YEAR = year))\n",
    "        \n",
    "        # Compute standard errors \n",
    "        df = df.assign(TOT_EMP_SE = lambda x: x.TOT_EMP * x.EMP_PRSE / 100,\n",
    "                  A_MEAN_SE = lambda x: x.A_MEAN * x.MEAN_PRSE / 100,\n",
    "                  A_MEDIAN_SE = lambda x: x.MEAN_PRSE * x.A_MEAN * 1.2533 / 100)\n",
    "        \n",
    "        # Compute margin of errors \n",
    "        df = df.assign(TOT_EMP_ME = lambda x: 1.96 * x.TOT_EMP_SE,\n",
    "                  A_MEAN_ME = lambda x: 1.96 * x.A_MEAN_SE,\n",
    "                  A_MEDIAN_ME = lambda x: 1.96 * x.A_MEDIAN_SE)\n",
    "        \n",
    "        # Select Math and CS Jobs, relevant columns, write to file and append to all data.\n",
    "        df = (df[(df.OCC_CODE == '15-0000')]\n",
    "              .drop(df.columns.difference(dfcols), axis = 1, inplace = False))\n",
    "        df.to_csv(path_or_buf = info['outFile'])        \n",
    "        allData.append(df)\n",
    "        \n",
    "    # Concatenate allData into single data frame\n",
    "    df = pd.concat(allData)\n",
    "        \n",
    "    # Dedup area names and set index \n",
    "    naics = df[['NAICS', 'NAICS_TITLE']]\n",
    "    naics = naics.loc[naics.duplicated(subset = ['NAICS']) == 0]\n",
    "    df = df.drop(['NAICS_TITLE'], axis=1)\n",
    "    df = df.merge(naics, how='left', on='NAICS')\n",
    "    df = df.rename(columns = {'NAICS_TITLE': 'Industry'})\n",
    "    df = df.set_index(\"Industry\")\n",
    "    \n",
    "    # Write to csv\n",
    "    df.to_csv(path_or_buf = natfile)\n",
    "    return df\n",
    "nat = prepNATData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepNAT2017():\n",
    "    cols = ['OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP', 'EMP_PRSE', 'A_MEAN', 'MEAN_PRSE', 'A_MEDIAN']\n",
    "    df = pd.read_excel(io = nat2017Data['excelfile'], sheetname = nat2017Data['sheet'], usecols = cols)\n",
    "    df = (df\n",
    "      .replace([\"**\", \"*\", \"#\"], pd.np.nan).dropna(axis=0, how = 'any',\n",
    "                                                  subset = ['TOT_EMP', 'EMP_PRSE',\n",
    "                                                            'A_MEAN', 'MEAN_PRSE',\n",
    "                                                            'A_MEDIAN'])\n",
    "      .apply(pd.to_numeric, errors = 'ignore'))\n",
    "    # Compute standard errors \n",
    "    df = df.assign(TOT_EMP_SE = lambda x: x.TOT_EMP * x.EMP_PRSE / 100,\n",
    "              A_MEAN_SE = lambda x: x.A_MEAN * x.MEAN_PRSE / 100,\n",
    "              A_MEDIAN_SE = lambda x: x.MEAN_PRSE * x.A_MEAN * 1.2533 / 100)\n",
    "    \n",
    "    # Compute margin of errors \n",
    "    df = df.assign(TOT_EMP_ME = lambda x: 1.96 * x.TOT_EMP_SE,\n",
    "              A_MEAN_ME = lambda x: 1.96 * x.A_MEAN_SE,                       \n",
    "              A_MEDIAN_ME = lambda x: 1.96 * x.A_MEDIAN_SE)\n",
    "    \n",
    "    # Select relevant occupation data\n",
    "    df = df[df['OCC_CODE'].str.contains(\"15-\")]\n",
    "    df = df[df['OCC_GROUP'] == 'detailed']\n",
    "    df = df.rename(columns = {'OCC_TITLE': 'Occupation'})\n",
    "    df = df.set_index(\"Occupation\")\n",
    "    \n",
    "    # Write to file\n",
    "    df.to_csv(path_or_buf = nat2017file)\n",
    "    return(df)\n",
    "nat2017 = prepNAT2017()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepOESData():\n",
    "    directory = \"./data/preprocessed\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    dfcols = ['YEAR', 'PRIM_STATE', 'AREA', 'AREA_NAME', 'OCC_CODE', 'OCC_TITLE', 'TOT_EMP',\n",
    "              'EMP_PRSE', 'JOBS_1000','A_MEAN', 'MEAN_PRSE', 'A_MEDIAN',\n",
    "              'TOT_EMP_SE', 'TOT_EMP_ME', 'JOBS_1000_SE','JOBS_1000_ME',\n",
    "              'A_MEAN_SE', 'A_MEAN_ME', 'A_MEDIAN_SE', 'A_MEDIAN_ME']\n",
    "    allData = []\n",
    "    for year, info in oesData.items():\n",
    "        \n",
    "        # Concatenate files\n",
    "        dfs = []\n",
    "        for file in info['inFiles']:\n",
    "            xl = pd.ExcelFile(info['inFiles'][file]['filename'])\n",
    "            pdf = xl.parse(info['inFiles'][file]['sheet'])\n",
    "            dfs.append(pdf)\n",
    "        df = pd.concat(dfs)\n",
    "        \n",
    "        # Remove NAs, missing values, and convert strings to numeric, and add year to dataframe\n",
    "        df = (df\n",
    "              .replace([\"**\", \"*\", \"#\"], pd.np.nan).dropna(axis=0, how = 'any',\n",
    "                                                          subset = ['TOT_EMP', 'EMP_PRSE',\n",
    "                                                                    'A_MEAN', 'MEAN_PRSE',\n",
    "                                                                    'A_MEDIAN'])\n",
    "              .apply(pd.to_numeric, errors = 'ignore')\n",
    "              .assign(YEAR = year))\n",
    "        \n",
    "        # Create JOBS_1000 variable for 2008 data\n",
    "        if (year == '2008'):\n",
    "            df2cols = ['AREA', 'TOT_EMP']\n",
    "            df2 =  (df[(df.OCC_CODE == '00-0000')]\n",
    "                    .drop(df.columns.difference(df2cols), axis = 1, inplace = False)\n",
    "                    .rename(columns = {'TOT_EMP': 'TOT_EMP_ALL'}))\n",
    "            df = (df.merge(df2, how = 'left', on = 'AREA')\n",
    "              .assign(JOBS_1000 = lambda x: x.TOT_EMP / (x.TOT_EMP_ALL/1000)))         \n",
    "                \n",
    "        # Compute standard errors \n",
    "        df = df.assign(TOT_EMP_SE = lambda x: x.TOT_EMP * x.EMP_PRSE / 100,\n",
    "                  JOBS_1000_SE = lambda x: x.JOBS_1000 * x.EMP_PRSE / 100,\n",
    "                  A_MEAN_SE = lambda x: x.A_MEAN * x.MEAN_PRSE / 100,\n",
    "                  A_MEDIAN_SE = lambda x: x.MEAN_PRSE * x.A_MEAN * 1.2533 / 100)\n",
    "        \n",
    "        # Compute margin of errors \n",
    "        df = df.assign(TOT_EMP_ME = lambda x: 1.96 * x.TOT_EMP_SE,\n",
    "                  JOBS_1000_ME = lambda x: 1.96 * x.JOBS_1000_SE,\n",
    "                  A_MEAN_ME = lambda x: 1.96 * x.A_MEAN_SE,                       \n",
    "                  A_MEDIAN_ME = lambda x: 1.96 * x.A_MEDIAN_SE)\n",
    "        \n",
    "        # Select Math and CS Jobs, relevant columns, write to file and append to all data.\n",
    "        df = (df[(df.OCC_CODE == '15-0000')]\n",
    "              .drop(df.columns.difference(dfcols), axis = 1, inplace = False))\n",
    "        df.to_csv(path_or_buf = info['outFile'])        \n",
    "        allData.append(df)\n",
    "        \n",
    "    # Concatenate allData into single data frame\n",
    "    df = pd.concat(allData)\n",
    "    \n",
    "    # Dedup area names and set index \n",
    "    areas = areas = df[['AREA', 'AREA_NAME']]\n",
    "    areas = areas.loc[areas.duplicated(subset = ['AREA']) == 0]\n",
    "    df = df.drop(['AREA_NAME'], axis=1)\n",
    "    df = df.merge(areas, how='left', on='AREA')\n",
    "    df = df.rename(columns = {'AREA_NAME': 'Market'})\n",
    "    df = df.set_index(\"Market\")\n",
    "    \n",
    "    # Write to csv\n",
    "    df.to_csv(path_or_buf = oesfile)\n",
    "    return df\n",
    "oes= prepOESData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepOES2017():\n",
    "    cols = ['OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'A_MEDIAN']\n",
    "    df = pd.read_excel(io = oesData['2017']['inFiles'][1]['filename'], \n",
    "                       sheetname =oesData['2017']['inFiles'][1]['sheet'], usecols = cols)\n",
    "    df = (df\n",
    "      .replace([\"**\", \"*\", \"#\"], pd.np.nan).dropna(axis=0, how = 'any',\n",
    "                                                  subset = ['A_MEDIAN'])\n",
    "      .apply(pd.to_numeric, errors = 'ignore'))  \n",
    "    \n",
    "    # Select relevant occupation data\n",
    "    df = df[df['OCC_CODE'].str.contains(\"15-\")]\n",
    "    df = df[df['OCC_GROUP'] == 'detailed']\n",
    "    df = df.rename(columns = {'OCC_TITLE': 'Occupation'})\n",
    "    df = df.set_index(\"Occupation\")\n",
    "    \n",
    "    # Write to file\n",
    "    df.to_csv(path_or_buf = 'data/preprocessed/oes2017all.csv')\n",
    "    return(df)\n",
    "oes2017all = prepOES2017()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
